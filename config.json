{
  "providers": {
    "openai": {
      "api_key": "${OPENAI_API_KEY}",
      "base_url": "https://api.openai.com/v1",
      "default_model": "gpt-4o-mini",
      "timeout": 120,
      "max_retries": 3,
      "retry_delay": 1.0,
      "rate_limit": {
        "requests_per_minute": 500,
        "tokens_per_minute": 150000
      }
    },
    "anthropic": {
      "api_key": "${ANTHROPIC_API_KEY}",
      "base_url": "https://api.anthropic.com",
      "default_model": "claude-3-5-sonnet-20241022",
      "timeout": 120,
      "max_retries": 3,
      "retry_delay": 1.0,
      "rate_limit": {
        "requests_per_minute": 100,
        "tokens_per_minute": 50000
      }
    },
    "ollama": {
      "base_url": "http://localhost:11434",
      "default_model": "llama3.2:3b",
      "timeout": 300,
      "max_retries": 2,
      "retry_delay": 2.0
    },
    "huggingface": {
      "api_key": "${HUGGINGFACE_API_KEY}",
      "base_url": "https://api-inference.huggingface.co",
      "default_model": "microsoft/DialoGPT-medium",
      "timeout": 120,
      "max_retries": 3,
      "retry_delay": 1.0
    }
  },
  "profiles": {
    "research-openai": {
      "provider": "openai",
      "model": "gpt-4o",
      "temperature": 0.0,
      "max_tokens": 4000,
      "top_p": 1.0,
      "frequency_penalty": 0.0,
      "presence_penalty": 0.0,
      "request_timeout": 120,
      "description": "High-quality research profile using OpenAI GPT-4o"
    },
    "production-anthropic": {
      "provider": "anthropic",
      "model": "claude-3-5-sonnet-20241022",
      "temperature": 0.0,
      "max_tokens": 4000,
      "top_p": 1.0,
      "request_timeout": 120,
      "description": "Production profile using Anthropic Claude"
    },
    "local-development": {
      "provider": "ollama",
      "model": "llama3.2:3b",
      "temperature": 0.1,
      "max_tokens": 2000,
      "top_p": 0.9,
      "request_timeout": 300,
      "description": "Local development profile using Ollama"
    },
    "fast-gpt35": {
      "provider": "openai",
      "model": "gpt-3.5-turbo",
      "temperature": 0.0,
      "max_tokens": 2000,
      "top_p": 1.0,
      "frequency_penalty": 0.0,
      "presence_penalty": 0.0,
      "request_timeout": 60,
      "description": "Fast and cost-effective profile using GPT-3.5"
    },
    "creative-anthropic": {
      "provider": "anthropic",
      "model": "claude-3-5-sonnet-20241022",
      "temperature": 0.7,
      "max_tokens": 4000,
      "top_p": 0.9,
      "request_timeout": 120,
      "description": "Creative profile using Anthropic Claude with higher temperature"
    },
    "local-llama": {
      "provider": "ollama",
      "model": "llama3.2:8b",
      "temperature": 0.2,
      "max_tokens": 3000,
      "top_p": 0.8,
      "request_timeout": 300,
      "description": "Local Llama 8B model for more capable local processing"
    }
  },
  "plugins": {
    "logitranslate": {
      "profile": "research-openai",
      "technique_params": {
        "validation_enabled": true,
        "max_attempts": 3,
        "retry_delay": 1.0,
        "schema_strict": true
      }
    },
    "logiattack": {
      "profile": "research-openai",
      "technique_params": {
        "validation_enabled": true,
        "schema_strict": true,
        "max_attempts": 2
      }
    },
    "judge": {
      "profile": "production-anthropic",
      "technique_params": {
        "threshold": 0.8,
        "multi_judge": true,
        "strict_evaluation": true
      }
    },
    "boost": {
      "technique_params": {
        "mode": "append",
        "num_eos": 5,
        "eos_token": "</s>",
        "storage_dir": "boost_results"
      }
    },
    "flipattack": {
      "technique_params": {
        "mode": "char",
        "storage_dir": "flipattack_results"
      }
    }
  },
  "logging": {
    "level": "INFO",
    "save_artifacts": true,
    "debug_mode": false
  },
  "storage": {
    "save_runs": true,
    "output_directory": "runs",
    "max_saved_runs": 100
  }
}